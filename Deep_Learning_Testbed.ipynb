{
  "cells": [
    {
      "metadata": {
        "_uuid": "cd88bd06bbaa8955a8775f13b9e56d58b260c687"
      },
      "cell_type": "markdown",
      "source": "# Deep Learning Homework\nBuild a dense neural network of one or more layers with at least 10 neurons per layer and use this network to predict the iris species in the Iris dataset.\n\nYour final layer will need 3 neurons and to use softmax activation.  You will also need to use categorical_crossentropy for your loss and prioritize accuracy as the metric.  This means a lot of the model will be more similar to the MNIST prediction, since both are classification problems, rather than regression problems like the house price challenge."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import datasets\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras import backend as K\n\niris = datasets.load_iris()",
      "execution_count": 183,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6953f494f1c7177354709687f698f7f8f45ecc61"
      },
      "cell_type": "code",
      "source": "X = iris.data\ny = iris.target\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y)",
      "execution_count": 184,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35256e4b2a2901bc15fa2c65b4b27556716e3f13"
      },
      "cell_type": "code",
      "source": "batch_size = 30   # this refers to the number of training examples utilised in one iteration. The size of a batch must be \n                  #    1 >= batch size <= number of samples in the training dataset.\nnum_classes = 3   # this is the number of classes in the output. In our case we have 3 distinct classes\nepochs = 20       # this refers to number of complete passes through the training dataset. ",
      "execution_count": 185,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf2008b537c83fd7cb8f37d5946f452024cb8f12"
      },
      "cell_type": "code",
      "source": "#X_train = X_train.astype('float32')\n#X_test = X_test.astype('float32')\n#X_train /= 8\n#X_test /= 8\n\n# one hot encodes the labels\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)",
      "execution_count": 186,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5075598276bfe91d1667c28d32088a346c756d3f"
      },
      "cell_type": "code",
      "source": "model = Sequential()\n#model.add(Flatten()) # convert 2-dimensional data to 1-dimensional data\nmodel.add(Dense(20, activation='relu'))\n#model.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax')) #softmax - when using multiple classes\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(X_test, y_test))\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])",
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 112 samples, validate on 38 samples\nEpoch 1/20\n112/112 [==============================] - 1s 7ms/step - loss: 2.2816 - acc: 0.3214 - val_loss: 1.9973 - val_acc: 0.3684\nEpoch 2/20\n112/112 [==============================] - 0s 72us/step - loss: 1.9628 - acc: 0.3214 - val_loss: 1.7388 - val_acc: 0.3684\nEpoch 3/20\n112/112 [==============================] - 0s 76us/step - loss: 1.6826 - acc: 0.3214 - val_loss: 1.5282 - val_acc: 0.3684\nEpoch 4/20\n112/112 [==============================] - 0s 78us/step - loss: 1.4596 - acc: 0.3214 - val_loss: 1.3609 - val_acc: 0.3684\nEpoch 5/20\n112/112 [==============================] - 0s 86us/step - loss: 1.2889 - acc: 0.3214 - val_loss: 1.2311 - val_acc: 0.3684\nEpoch 6/20\n112/112 [==============================] - 0s 71us/step - loss: 1.1593 - acc: 0.3214 - val_loss: 1.1339 - val_acc: 0.3684\nEpoch 7/20\n112/112 [==============================] - 0s 74us/step - loss: 1.0634 - acc: 0.3214 - val_loss: 1.0545 - val_acc: 0.3684\nEpoch 8/20\n112/112 [==============================] - 0s 65us/step - loss: 0.9889 - acc: 0.3214 - val_loss: 0.9904 - val_acc: 0.3684\nEpoch 9/20\n112/112 [==============================] - 0s 71us/step - loss: 0.9310 - acc: 0.3304 - val_loss: 0.9382 - val_acc: 0.3684\nEpoch 10/20\n112/112 [==============================] - 0s 70us/step - loss: 0.8845 - acc: 0.3393 - val_loss: 0.8949 - val_acc: 0.3947\nEpoch 11/20\n112/112 [==============================] - 0s 78us/step - loss: 0.8485 - acc: 0.4464 - val_loss: 0.8568 - val_acc: 0.4474\nEpoch 12/20\n112/112 [==============================] - 0s 91us/step - loss: 0.8183 - acc: 0.4554 - val_loss: 0.8257 - val_acc: 0.4474\nEpoch 13/20\n112/112 [==============================] - 0s 80us/step - loss: 0.7930 - acc: 0.5625 - val_loss: 0.8019 - val_acc: 0.6053\nEpoch 14/20\n112/112 [==============================] - 0s 76us/step - loss: 0.7744 - acc: 0.7143 - val_loss: 0.7789 - val_acc: 0.7895\nEpoch 15/20\n112/112 [==============================] - 0s 77us/step - loss: 0.7561 - acc: 0.8125 - val_loss: 0.7566 - val_acc: 0.8158\nEpoch 16/20\n112/112 [==============================] - 0s 80us/step - loss: 0.7400 - acc: 0.8482 - val_loss: 0.7408 - val_acc: 0.8158\nEpoch 17/20\n112/112 [==============================] - 0s 77us/step - loss: 0.7247 - acc: 0.8839 - val_loss: 0.7224 - val_acc: 0.8421\nEpoch 18/20\n112/112 [==============================] - 0s 81us/step - loss: 0.7108 - acc: 0.8661 - val_loss: 0.7070 - val_acc: 0.8421\nEpoch 19/20\n112/112 [==============================] - 0s 84us/step - loss: 0.6982 - acc: 0.8839 - val_loss: 0.6901 - val_acc: 0.8421\nEpoch 20/20\n112/112 [==============================] - 0s 83us/step - loss: 0.6857 - acc: 0.8839 - val_loss: 0.6773 - val_acc: 0.8421\nTest loss: 0.6772964157556233\nTest accuracy: 0.8421052600208082\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4342225377b1c6cf3c7b6a1c5146b6e3a3cc7ead"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}